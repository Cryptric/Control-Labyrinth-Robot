{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-19T07:22:09.604385Z",
     "start_time": "2024-05-19T07:22:09.598387Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "if os.getcwd().endswith(\"Nets\"):\n",
    "    os.chdir(\"..\")"
   ],
   "id": "c97cc5514b8907ab",
   "execution_count": 1,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-05-19T07:24:13.321578Z",
     "start_time": "2024-05-19T07:24:13.267433Z"
    }
   },
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms.functional as TF\n",
    "from torch.utils.data import TensorDataset, random_split, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.stats import multivariate_normal\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import PIL.Image\n",
    "from tqdm import tqdm\n",
    "\n",
    "from utils.FrameUtils import remove_distortion\n",
    "from utils.ControlUtils import calc_distance\n",
    "from Params import *\n",
    "import CueNetV2"
   ],
   "execution_count": 6,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-19T07:24:15.285980Z",
     "start_time": "2024-05-19T07:24:15.278445Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def train_epoch(model, train_loader, device, optimiser, loss_fn):\n",
    "    model.train()\n",
    "    total_loss, count = 0, 0\n",
    "    for features, labels in tqdm(train_loader):\n",
    "        features, labels = features.to(device), labels.to(device)\n",
    "        predictions = model(features)\n",
    "        loss = loss_fn(predictions, labels)\n",
    "        total_loss += loss\n",
    "        \n",
    "        optimiser.zero_grad()\n",
    "        loss.backward()\n",
    "        optimiser.step()\n",
    "        \n",
    "        count += len(labels)\n",
    "    return total_loss.item() / count\n",
    "\n",
    "\n",
    "def test_epoch(model, test_loader, device, loss_fn):\n",
    "    model.eval()\n",
    "    total_loss, count = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for features, labels in test_loader:\n",
    "            features, labels = features.to(device), labels.to(device)\n",
    "            predictions = model(features)\n",
    "            \n",
    "            total_loss += loss_fn(predictions, labels)\n",
    "            count += len(labels)\n",
    "    return total_loss.item() / count\n",
    "\n",
    "def train(model, train_loader, test_loader, device, optimiser, loss_fn, epochs=10):\n",
    "    res = { 'train_loss': [], 'test_loss': []}\n",
    "    for ep in range(epochs):\n",
    "        train_loss = train_epoch(model, train_loader, device, optimiser, loss_fn)\n",
    "        test_loss = test_epoch(model, test_loader, device, loss_fn)\n",
    "        \n",
    "        print(f\"Epoch {ep:2}, Train loss={train_loss:.7f}, test loss={test_loss:.7f}\")\n",
    "        res['train_loss'].append(train_loss)\n",
    "        res['test_loss'].append(test_loss)\n",
    "    return res\n"
   ],
   "id": "f3e8c2182f268b45",
   "execution_count": 7,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-19T07:24:16.475033Z",
     "start_time": "2024-05-19T07:24:16.450031Z"
    }
   },
   "cell_type": "code",
   "source": [
    "data_index = pd.read_csv(\"MLData/labels.csv\", header=None)\n",
    "data_index"
   ],
   "id": "7944c56ace37f264",
   "execution_count": 8,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-19T07:24:19.748782Z",
     "start_time": "2024-05-19T07:24:19.744393Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def create_label(x_pos, y_pos, variance=10, img_width=240, img_height=180):\n",
    "    x = np.arange(img_width)\n",
    "    y = np.arange(img_height)\n",
    "    X, Y = np.meshgrid(x, y)\n",
    "    mu = np.array([x_pos, y_pos])\n",
    "    sigma = np.array([[variance, 0], [0, variance]])\n",
    "    pos = np.empty(X.shape + (2,))\n",
    "    pos[:, :, 0] = X\n",
    "    pos[:, :, 1] = Y\n",
    "    rv = multivariate_normal(mu, sigma)\n",
    "    pd = rv.pdf(pos)\n",
    "    return torch.from_numpy(pd)"
   ],
   "id": "bfffb9801d2b969c",
   "execution_count": 9,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-19T07:24:20.388393Z",
     "start_time": "2024-05-19T07:24:20.382447Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def load_img(path):\n",
    "    img = PIL.Image.open(path)\n",
    "    img.load()\n",
    "    return np.asarray(img, dtype=np.uint8)\n",
    "\n",
    "def preprocess_img(img):\n",
    "    img = remove_distortion(img)\n",
    "    img = cv2.equalizeHist(img)\n",
    "    return torch.squeeze(TF.to_tensor(img[PROCESSING_Y:PROCESSING_Y+PROCESSING_SIZE_HEIGHT, PROCESSING_X:PROCESSING_X+PROCESSING_SIZE_WIDTH].astype(np.float32) / 255))\n",
    "\n",
    "def flip_h(img_stack):\n",
    "    return torch.flip(img_stack, [2])\n",
    "\n",
    "def flip_v(img_stack):\n",
    "    return torch.flip(img_stack, [1])\n",
    "\n",
    "def flip_hv(img_stack):\n",
    "    return torch.flip(img_stack, [1, 2])\n",
    "\n",
    "def get_noise(size, mean= 0, std=0.1):\n",
    "    return torch.randn(size) * std + mean\n",
    "\n",
    "def create_variations(sample, label):\n",
    "    size = sample.size()\n",
    "    s_h = flip_h(sample) + get_noise(size)\n",
    "    l_h = torch.flip(label, [1])\n",
    "    s_v = flip_v(sample) + get_noise(size)\n",
    "    l_v = torch.flip(label, [0])\n",
    "    s_hv = flip_hv(sample) + get_noise(size)\n",
    "    l_hv = torch.flip(label, [0, 1])\n",
    "    return s_h, l_h, s_v, l_v, s_hv, l_hv"
   ],
   "id": "84262b7b72d99529",
   "execution_count": 10,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-19T07:25:22.796581Z",
     "start_time": "2024-05-19T07:24:21.484479Z"
    }
   },
   "cell_type": "code",
   "source": [
    "frame_queue = [None] * 2\n",
    "\n",
    "data = []\n",
    "labels = []\n",
    "\n",
    "for index, row in tqdm(data_index.iterrows(), total=data_index.shape[0]):\n",
    "    img_name = row[0]\n",
    "    pos_x = row[1]\n",
    "    pos_y = row[2]\n",
    "    if pos_x == 0 and pos_y == 0:\n",
    "        frame_queue.pop(0)\n",
    "        frame_queue.append(None)\n",
    "    else:\n",
    "        pos_x = row[1] - PROCESSING_X\n",
    "        pos_y = row[2] - PROCESSING_Y\n",
    "        frame = preprocess_img(load_img(img_name))\n",
    "        label = create_label(pos_x, pos_y)\n",
    "        if (not frame_queue[0] is None) and (not frame_queue[1] is None):\n",
    "            sample = torch.stack((frame, frame_queue[0], frame_queue[1]))\n",
    "            size = sample.size()\n",
    "            data.append(sample + get_noise(size))\n",
    "            labels.append(label)\n",
    "            \n",
    "            s_h, l_h, s_v, l_v, s_hv, l_hv = create_variations(sample, label)\n",
    "            data.extend((s_h, s_v, s_hv))\n",
    "            labels.extend((l_h, l_v, l_hv))\n",
    "        sample = torch.stack((frame, frame, frame))\n",
    "        data.append(sample + get_noise(sample.size()))\n",
    "        labels.append(label)\n",
    "        s_h, l_h, s_v, l_v, s_hv, l_hv = create_variations(sample, label)\n",
    "        data.extend((s_h, s_v, s_hv))\n",
    "        labels.extend((l_h, l_v, l_hv))\n",
    "        \n",
    "        frame_queue.pop(0)\n",
    "        frame_queue.append(frame)\n",
    "\n",
    "print(f\"Loaded {len(data)} training samples\")"
   ],
   "id": "25b3717906a96a24",
   "execution_count": 11,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-19T07:29:23.797033Z",
     "start_time": "2024-05-19T07:29:19.995705Z"
    }
   },
   "cell_type": "code",
   "source": "dataset = TensorDataset(torch.stack(data, dim=0), torch.stack(labels, dim=0))",
   "id": "700b125e3e4df4a0",
   "execution_count": 16,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-19T07:29:30.435941Z",
     "start_time": "2024-05-19T07:29:29.996641Z"
    }
   },
   "cell_type": "code",
   "source": [
    "fig, ax = plt.subplots(ncols=4)\n",
    "features, label = next(iter(dataset))\n",
    "print(features.shape)\n",
    "ax[0].imshow(features[0], cmap='gray')\n",
    "ax[1].imshow(features[1], cmap='gray')\n",
    "ax[2].imshow(features[2], cmap='gray')\n",
    "ax[3].imshow(label, cmap='Reds')"
   ],
   "id": "3b1a9b9020047ccb",
   "execution_count": 17,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-19T07:29:35.351413Z",
     "start_time": "2024-05-19T07:29:35.347013Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def plot(features, prediction, label):\n",
    "    fig, ax = plt.subplots(ncols=5)\n",
    "    ax[0].imshow(features[0], cmap='gray')\n",
    "    ax[1].imshow(features[1], cmap='gray')\n",
    "    ax[2].imshow(features[2], cmap='gray')\n",
    "    ax[3].imshow(prediction, cmap='Reds')\n",
    "    ax[3].set_title(\"prediction\")\n",
    "    ax[4].imshow(label, cmap='Reds')\n",
    "    ax[4].set_title(\"label\")\n",
    "\n",
    "def plot_sample(data_loader, model):\n",
    "    features, labels = next(iter(data_loader))\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        prediction = model(torch.unsqueeze(features[0].to(device), 0)).cpu().detach()\n",
    "    plot(features[0], prediction[0], labels[0])"
   ],
   "id": "afa71925b0d3c77e",
   "execution_count": 18,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-19T07:29:36.489201Z",
     "start_time": "2024-05-19T07:29:36.482067Z"
    }
   },
   "cell_type": "code",
   "source": [
    "batch_size = 16\n",
    "train_dataset, test_dataset, validation_dataset = random_split(dataset, [0.8, 0.1, 0.1])\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)\n",
    "validation_loader = DataLoader(validation_dataset, batch_size=batch_size, shuffle=True)\n",
    "print(f\"Train set size:     {len(train_dataset)}\")\n",
    "print(f\"Test set size:       {len(test_dataset)}\")\n",
    "print(f\"Validation set size: {len(validation_dataset)}\")"
   ],
   "id": "9f6dc01ff1dc01a0",
   "execution_count": 19,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-19T07:29:40.062875Z",
     "start_time": "2024-05-19T07:29:39.838830Z"
    }
   },
   "cell_type": "code",
   "source": "model = CueNetV2.load_cue_net_v2()",
   "id": "604d81375d0e4105",
   "execution_count": 20,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-19T07:29:42.636593Z",
     "start_time": "2024-05-19T07:29:42.633594Z"
    }
   },
   "cell_type": "code",
   "source": "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")",
   "id": "b9631eae36a7e812",
   "execution_count": 21,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-19T07:29:44.331990Z",
     "start_time": "2024-05-19T07:29:44.328860Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def plot_all(data_loader, model):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for features, labels in data_loader:\n",
    "            predictions = model(features.to(device)).cpu().detach()\n",
    "            for i in range(batch_size):\n",
    "                plot(features[i], predictions[i], labels[i])\n",
    "                plt.show()\n",
    "            break"
   ],
   "id": "e76f5d791a7c9371",
   "execution_count": 22,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-19T07:29:55.598983Z",
     "start_time": "2024-05-19T07:29:45.186474Z"
    }
   },
   "cell_type": "code",
   "source": "plot_all(validation_loader, model)",
   "id": "fc52cd9edf31e511",
   "execution_count": 23,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-19T07:30:00.071769Z",
     "start_time": "2024-05-19T07:30:00.068373Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def find_center(pdf, template_size=13):\n",
    "    center = int(template_size / 2)\n",
    "    template = create_label(center, center, img_width=template_size, img_height=template_size).numpy()\n",
    "    template = template.astype(np.float32)\n",
    "    res = cv2.matchTemplate(pdf.astype(np.float32), template, method=cv2.TM_SQDIFF)\n",
    "    min_val, max_val, min_loc, max_loc = cv2.minMaxLoc(res)\n",
    "    min_x, min_y = min_loc\n",
    "    return min_x + center, min_y + center"
   ],
   "id": "5d56c8b0ecb89770",
   "execution_count": 24,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-19T07:30:00.735041Z",
     "start_time": "2024-05-19T07:30:00.708041Z"
    }
   },
   "cell_type": "code",
   "source": "find_center(create_label(40, 50).numpy().astype(np.float32))",
   "id": "522a4957869eb8fa",
   "execution_count": 25,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-19T07:30:02.530348Z",
     "start_time": "2024-05-19T07:30:01.713553Z"
    }
   },
   "cell_type": "code",
   "source": [
    "features, labels = next(iter(validation_loader))\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    prediction = model(torch.unsqueeze(features[0].to(device), 0)).cpu().detach()\n",
    "    plt.imshow(prediction[0], cmap=\"Reds\")\n",
    "    x, y = find_center(prediction[0].numpy())\n",
    "    plt.scatter(x, y)"
   ],
   "id": "7d7712426dc71a4b",
   "execution_count": 26,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-19T07:30:05.742570Z",
     "start_time": "2024-05-19T07:30:05.738991Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def se_distance(data_loader, model):\n",
    "    errors = []\n",
    "    with torch.no_grad():\n",
    "        for features, labels in data_loader:\n",
    "            predictions = model(features.to(device)).detach().cpu().numpy()\n",
    "            for i in range(predictions.shape[0]):\n",
    "                predicted_pos = np.array(find_center(predictions[i]))\n",
    "                label_pos = np.array(find_center(labels[i].numpy()))\n",
    "                errors.append(calc_distance(predicted_pos, label_pos) ** 2)\n",
    "    return errors"
   ],
   "id": "4ea59a4938c81300",
   "execution_count": 27,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-19T07:30:21.776512Z",
     "start_time": "2024-05-19T07:30:07.277995Z"
    }
   },
   "cell_type": "code",
   "source": [
    "counts, bins = np.histogram(se_distance(validation_loader, model))\n",
    "plt.hist(bins[:-1], bins, weights=counts)"
   ],
   "id": "96babdeb7e79b15f",
   "execution_count": 28,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-19T08:28:02.079568Z",
     "start_time": "2024-05-19T08:19:38.503693Z"
    }
   },
   "cell_type": "code",
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "loss_fn = nn.L1Loss(reduction='sum')\n",
    "\n",
    "num_epochs = 2\n",
    "\n",
    "res = train(model, train_loader, test_loader, device, optimizer, loss_fn, num_epochs)\n",
    "\n",
    "plt.plot(np.arange(num_epochs), res['train_loss'], label='train loss')\n",
    "plt.plot(np.arange(num_epochs), res['test_loss'], label='test loss')"
   ],
   "id": "31b9fbddcaee1918",
   "execution_count": 59,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-19T08:36:18.570939Z",
     "start_time": "2024-05-19T08:36:13.398580Z"
    }
   },
   "cell_type": "code",
   "source": "plot_all(validation_loader, model)",
   "id": "bf2904f5fc137be3",
   "execution_count": 60,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-19T08:36:43.849581Z",
     "start_time": "2024-05-19T08:36:23.857604Z"
    }
   },
   "cell_type": "code",
   "source": [
    "s_distances = se_distance(validation_loader, model)\n",
    "print(np.mean(s_distances))\n",
    "counts, bins = np.histogram(s_distances)\n",
    "plt.hist(bins[:-1], bins, weights=counts, log=True)"
   ],
   "id": "78273724d1f901d7",
   "execution_count": 61,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-19T08:19:13.674947Z",
     "start_time": "2024-05-19T08:19:13.640590Z"
    }
   },
   "cell_type": "code",
   "source": "torch.save({'state_dict': model.state_dict()}, 'Nets/4ep.pt')",
   "id": "80026b3306e23768",
   "execution_count": 58,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "execution_count": null,
   "source": "",
   "id": "bec4182a3f75f521",
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
